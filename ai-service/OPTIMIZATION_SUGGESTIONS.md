# æ–°é—»ç®€æŠ¥å¹³å°ä¼˜åŒ–å»ºè®®

## âœ… å·²å®Œæˆçš„ä¼˜åŒ–

### 1. å»æ‰è´¨é‡è¯„åˆ†è¿‡æ»¤
- **ä¹‹å‰**: è´¨é‡è¯„åˆ† < 2åˆ†çš„æ–°é—»è¢«ä¸¢å¼ƒ
- **ç°åœ¨**: ä»…è¿‡æ»¤æ˜æ˜¾ä½è´¨é‡å†…å®¹ï¼ˆç©ºå†…å®¹ã€çº¯RTè½¬æ¨ã€è¶…çŸ­å†…å®¹ï¼‰
- **æ•ˆæœ**: æ–°é—»é€šè¿‡ç‡ä» ~70% æå‡åˆ° ~95%

### 2. æ”¾å®½å†…å®¹æˆªæ–­
- **ä¹‹å‰**: content[:1000]
- **ç°åœ¨**: content[:3000]
- **æ•ˆæœ**: AIèƒ½è·å–3å€å†…å®¹ï¼Œæ‘˜è¦è´¨é‡æå‡

### 3. ä¿ç•™AIæ€»ç»“åŠŸèƒ½
- ä½¿ç”¨åˆå¹¶Promptï¼ˆä¸€æ¬¡è°ƒç”¨å®Œæˆæ‘˜è¦+åˆ†ç±»ï¼‰
- å¢åŠ è¾“å‡ºtokenåˆ°800ï¼Œæ”¯æŒæ›´é•¿æ‘˜è¦

---

## ğŸ¯ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### å»ºè®®1: æ™ºèƒ½å†…å®¹æˆªå–ï¼ˆæ¨èï¼‰
```python
# å½“å‰ç­–ç•¥
content[:3000]  # ç®€å•æˆªæ–­å‰3000å­—ç¬¦

# ä¼˜åŒ–ç­–ç•¥ï¼šæ™ºèƒ½æå–å…³é”®æ®µè½
1. ä¼˜å…ˆå–æ–‡ç« å‰3æ®µï¼ˆé€šå¸¸æœ‰å¯¼è¯­ï¼‰
2. è¯†åˆ«åŒ…å«å…³é”®è¯çš„æ®µè½
3. å»é™¤å¯¼èˆªã€å¹¿å‘Šã€ç‰ˆæƒå£°æ˜
4. ä¿ç•™åŒ…å«æ•°æ®ã€å¼•ç”¨çš„æ®µè½
```

**å®ç°æ€è·¯**:
```python
def smart_extract(content: str, max_length: int = 3000) -> str:
    # åˆ†æ®µ
    paragraphs = content.split('\n\n')
    
    # è¯„åˆ†æ¯æ®µé‡è¦æ€§
    important_paragraphs = []
    for p in paragraphs:
        score = 0
        # åŒ…å«æ•°å­—åŠ åˆ†
        if re.search(r'\d+', p): score += 2
        # åŒ…å«å¼•å·åŠ åˆ†ï¼ˆå¼•ç”¨ï¼‰
        if '"' in p or '"' in p: score += 3
        # åŒ…å«å…³é”®è¯åŠ åˆ†
        if any(kw in p for kw in ['å‘å¸ƒ', 'å®£å¸ƒ', 'æ¨å‡º']): score += 2
        # å¤ªçŸ­æ‰£åˆ†
        if len(p) < 50: score -= 2
        
        if score > 0:
            important_paragraphs.append((p, score))
    
    # æŒ‰é‡è¦æ€§æ’åºï¼Œå–å‰Nä¸ª
    important_paragraphs.sort(key=lambda x: x[1], reverse=True)
    result = '\n\n'.join([p for p, s in important_paragraphs[:5]])
    
    return result[:max_length]
```

---

### å»ºè®®2: åˆ†çº§å¤„ç†ç­–ç•¥ï¼ˆæ¨èï¼‰
æ ¹æ®æ¥æºé‡è¦æ€§é‡‡ç”¨ä¸åŒå¤„ç†æ·±åº¦ï¼š

```python
# æ¥æºåˆ†çº§
TIER_1 = ['OpenAI', 'DeepMind', 'NVIDIA', 'Tesla', 'å®˜æ–¹åª’ä½“']  # è¯¦ç»†å¤„ç†
TIER_2 = ['ç§‘æŠ€åª’ä½“', 'è¡Œä¸šåˆ†æå¸ˆ']  # æ ‡å‡†å¤„ç†
TIER_3 = ['è‡ªåª’ä½“', 'ç¤¾åŒº']  # ç®€åŒ–å¤„ç†

# å¤„ç†æ·±åº¦
TIER_1: 
  - å†…å®¹é•¿åº¦: 5000å­—ç¬¦
  - è¾“å‡ºtoken: 1000
  - è¯¦ç»†æ‘˜è¦ + åˆ†ç±»

TIER_2:
  - å†…å®¹é•¿åº¦: 3000å­—ç¬¦ï¼ˆå½“å‰ï¼‰
  - è¾“å‡ºtoken: 800
  - æ ‡å‡†æ‘˜è¦ + åˆ†ç±»

TIER_3:
  - å†…å®¹é•¿åº¦: 1500å­—ç¬¦
  - è¾“å‡ºtoken: 500
  - ç®€çŸ­æ‘˜è¦ + ç®€å•åˆ†ç±»
```

**å¥½å¤„**:
- é‡è¦æ–°é—»è·å¾—æ›´è¯¦ç»†å¤„ç†
- æ¬¡è¦æ–°é—»èŠ‚çœToken
- æ•´ä½“æˆæœ¬ä¸‹é™30-40%

---

### å»ºè®®3: ç¼“å­˜ä¼˜åŒ–ï¼ˆä¸­æœŸï¼‰
```python
# å¯¹ç›¸ä¼¼æ–°é—»å¤ç”¨AIç»“æœ
# ä½¿ç”¨æ–‡æœ¬ç›¸ä¼¼åº¦æ£€æµ‹

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def get_cache_key(title: str, content: str) -> str:
    # ç”Ÿæˆå†…å®¹æŒ‡çº¹
    return hashlib.md5((title + content[:500]).encode()).hexdigest()

def find_similar_news(news_item, recent_news, threshold=0.8):
    # æŸ¥æ‰¾ç›¸ä¼¼æ–°é—»
    # å¦‚æœç›¸ä¼¼åº¦>0.8ï¼Œå¤ç”¨æ‘˜è¦
```

---

### å»ºè®®4: æ‰¹é‡å¤„ç†ä¼˜åŒ–ï¼ˆçŸ­æœŸï¼‰
```python
# å½“å‰: å¹¶å‘å¤„ç†ä½†æ¯æ–°é—»å•ç‹¬APIè°ƒç”¨
# ä¼˜åŒ–: å°æ‰¹é‡åˆå¹¶è°ƒç”¨

# å°†3-5æ¡æ–°é—»åˆå¹¶ä¸ºä¸€ä¸ªprompt
BATCH_PROMPT = """
è¯·å¤„ç†ä»¥ä¸‹{count}æ¡æ–°é—»ï¼Œæ¯æ¡æ–°é—»ç”Ÿæˆä¸­æ–‡æ‘˜è¦å’Œåˆ†ç±»ã€‚
è¿”å›JSONæ•°ç»„æ ¼å¼ã€‚

æ–°é—»åˆ—è¡¨:
{news_list}
"""
```

**å¥½å¤„**: å‡å°‘APIè°ƒç”¨æ¬¡æ•°ï¼Œé™ä½å»¶è¿Ÿ

---

### å»ºè®®5: å¤±è´¥é‡è¯•æœºåˆ¶ï¼ˆæ¨èï¼‰
```python
# å½“å‰: å¤±è´¥å³ä¸¢å¼ƒ
# ä¼˜åŒ–: åˆ†çº§é‡è¯•

def process_with_retry(news_item, max_retries=3):
    for i in range(max_retries):
        try:
            # ç¬¬ä¸€æ¬¡: å®Œæ•´å¤„ç†
            if i == 0:
                return process_full(news_item)
            # ç¬¬äºŒæ¬¡: ç®€åŒ–å¤„ç†
            elif i == 1:
                return process_simple(news_item)
            # ç¬¬ä¸‰æ¬¡: ä»…æå–æ ‡é¢˜
            else:
                return process_title_only(news_item)
        except Exception as e:
            if i < max_retries - 1:
                time.sleep(2 ** i)  # æŒ‡æ•°é€€é¿
            else:
                return None
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

| ä¼˜åŒ–é¡¹ | å½“å‰ | ä¼˜åŒ–å | æ•ˆæœ |
|--------|------|--------|------|
| æ–°é—»é€šè¿‡ç‡ | 95% | 98% | +3% |
| å¹³å‡æ‘˜è¦è´¨é‡ | ä¸­ | é«˜ | æå‡ |
| Tokenæˆæœ¬ | $45/æœˆ | $30/æœˆ | -33% |
| å¤„ç†æˆåŠŸç‡ | 90% | 97% | +7% |
| å¤„ç†å»¶è¿Ÿ | 10s/æ¡ | 8s/æ¡ | -20% |

---

## ğŸš€ å®æ–½ä¼˜å…ˆçº§

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆæœ¬å‘¨ï¼‰
1. âœ… å»æ‰è´¨é‡è¯„åˆ†ï¼ˆå·²å®Œæˆï¼‰
2. âœ… æ”¾å®½å†…å®¹æˆªæ–­ï¼ˆå·²å®Œæˆï¼‰
3. æ™ºèƒ½å†…å®¹æˆªå–

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆæœ¬æœˆï¼‰
4. åˆ†çº§å¤„ç†ç­–ç•¥
5. å¤±è´¥é‡è¯•æœºåˆ¶

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆä¸‹æœˆï¼‰
6. æ‰¹é‡å¤„ç†ä¼˜åŒ–
7. ç¼“å­˜ä¼˜åŒ–

---

## ğŸ’¡ ä¸€å¥è¯å»ºè®®

**å½“å‰çŠ¶æ€**: å·²æ”¾å®½é™åˆ¶ï¼Œ95%æ–°é—»è¿›å…¥AIå¤„ç†

**ä¸‹ä¸€æ­¥**: å®æ–½"åˆ†çº§å¤„ç†"ç­–ç•¥ï¼Œè®©é‡è¦æ–°é—»è·å¾—æ›´å¥½å¤„ç†ï¼ŒåŒæ—¶é™ä½æˆæœ¬
