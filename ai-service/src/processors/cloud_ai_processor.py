import requests
import json
from typing import Dict, Optional, List
import logging
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

logger = logging.getLogger(__name__)


class CloudAIProcessor:
    """ä½¿ç”¨äº‘ç«¯AI APIè¿›è¡Œå¤„ç†ï¼ˆOpenAI/Claude/HuggingFaceï¼‰"""

    def __init__(self, provider: str = 'openai'):
        self.provider = provider.lower()

        if self.provider == 'openai':
            self.api_key = os.getenv('OPENAI_API_KEY')
            self.api_url = 'https://api.openai.com/v1/chat/completions'
            self.model = os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo')
        elif self.provider == 'deepseek':
            # DeepSeekä¸­å›½AIï¼ˆè¶…ä¾¿å®œï¼Œå…¼å®¹OpenAIæ ¼å¼ï¼‰
            self.api_key = os.getenv('DEEPSEEK_API_KEY')
            self.api_url = 'https://api.deepseek.com/v1/chat/completions'
            self.model = os.getenv('DEEPSEEK_MODEL', 'deepseek-chat')
            logger.info("ä½¿ç”¨DeepSeek AIï¼ˆä¸­å›½ï¼‰")
        elif self.provider == 'kimi':
            # Kimi (Moonshot AI) - å…¼å®¹OpenAIæ ¼å¼
            self.api_key = os.getenv('KIMI_API_KEY')
            self.api_url = 'https://api.moonshot.cn/v1/chat/completions'
            self.model = os.getenv('KIMI_MODEL', 'moonshot-v1-8k')
            logger.info("ä½¿ç”¨Kimi AIï¼ˆMoonshotï¼‰")
        elif self.provider == 'claude':
            self.api_key = os.getenv('CLAUDE_API_KEY')
            self.api_url = 'https://api.anthropic.com/v1/messages'
            self.model = os.getenv('CLAUDE_MODEL', 'claude-3-haiku-20240307')
        elif self.provider == 'huggingface':
            # Hugging Faceå…è´¹æ¨ç†APIï¼ˆéœ€è¦æ³¨å†Œå…è´¹API Keyï¼‰
            self.api_key = os.getenv('HUGGINGFACE_API_KEY', '')
            if not self.api_key:
                logger.warning("æœªè®¾ç½®HUGGINGFACE_API_KEYï¼Œå°†ä½¿ç”¨åŸºç¡€æ–‡æœ¬å¤„ç†")
                self.api_key = 'no_api'  # æ ‡è®°ä¸ºæ— APIæ¨¡å¼
            self.api_url = 'https://api-inference.huggingface.co/models/google/flan-t5-xxl'
            self.model = 'google/flan-t5-xxl'
            logger.info("ä½¿ç”¨Hugging Face API")
            return  # è·³è¿‡API keyéªŒè¯
        else:
            raise ValueError(f"Unsupported provider: {provider}")

        if not self.api_key:
            raise ValueError(f"API key not found for {provider}")

    def _call_openai(self, prompt: str, max_tokens: int = 200) -> Optional[str]:
        """è°ƒç”¨OpenAI API"""
        try:
            if not self.api_key:
                logger.error(f"âŒ {self.provider.upper()} API Key æœªè®¾ç½®")
                logger.error(f"   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: {self.provider.upper()}_API_KEY")
                return None

            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': self.model,
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': max_tokens,
                'temperature': 0.3
            }

            logger.info(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ {self.provider} API (model: {self.model})...")
            logger.debug(f"   API URL: {self.api_url}")
            logger.debug(f"   Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            response = requests.post(
                self.api_url,
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                logger.info(f"âœ… {self.provider} API è°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(content)} å­—ç¬¦")
                logger.debug(f"   è¿”å›å†…å®¹é¢„è§ˆ: {content[:100]}...")
                return content
            else:
                logger.error(f"âŒ {self.provider} APIé”™è¯¯: {response.status_code}")
                logger.error(f"   å“åº”å†…å®¹: {response.text[:200]}")
                return None

        except requests.exceptions.Timeout:
            logger.error(f"âŒ {self.provider} API è°ƒç”¨è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
            return None
        except requests.exceptions.ConnectionError as e:
            logger.error(f"âŒ {self.provider} API è¿æ¥å¤±è´¥: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"âŒ {self.provider} è°ƒç”¨å¤±è´¥: {str(e)}")
            return None

    def _call_claude(self, prompt: str, max_tokens: int = 200) -> Optional[str]:
        """è°ƒç”¨Claude API"""
        try:
            headers = {
                'x-api-key': self.api_key,
                'anthropic-version': '2023-06-01',
                'Content-Type': 'application/json'
            }

            data = {
                'model': self.model,
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': max_tokens,
                'temperature': 0.3
            }

            response = requests.post(
                self.api_url,
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return result['content'][0]['text'].strip()
            else:
                logger.error(f"Claude APIé”™è¯¯: {response.status_code} - {response.text}")
                return None

        except Exception as e:
            logger.error(f"Claudeè°ƒç”¨å¤±è´¥: {str(e)}")
            return None

    def _call_huggingface(self, prompt: str, max_tokens: int = 200) -> Optional[str]:
        """è°ƒç”¨Hugging Faceå…è´¹æ¨ç†API"""
        try:
            # å¦‚æœæ²¡æœ‰API Keyï¼Œä½¿ç”¨ç®€å•çš„æ–‡æœ¬å¤„ç†ä½œä¸ºåå¤‡
            if self.api_key == 'no_api':
                logger.warning("æ— Hugging Face API Keyï¼Œè¿”å›åŸæ–‡")
                return None

            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {self.api_key}'
            }

            data = {
                'inputs': prompt,
                'parameters': {
                    'max_new_tokens': max_tokens,
                    'temperature': 0.3,
                    'do_sample': True
                }
            }

            response = requests.post(
                self.api_url,
                headers=headers,
                json=data,
                timeout=60  # Hugging Faceå…è´¹APIå¯èƒ½è¾ƒæ…¢
            )

            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    return result[0].get('generated_text', '').strip()
                elif isinstance(result, dict):
                    return result.get('generated_text', '').strip()
                return None
            elif response.status_code == 503:
                # æ¨¡å‹æ­£åœ¨åŠ è½½ï¼Œç­‰å¾…é‡è¯•
                logger.warning("Hugging Faceæ¨¡å‹æ­£åœ¨åŠ è½½ï¼Œç­‰å¾…10ç§’åé‡è¯•...")
                import time
                time.sleep(10)
                # é‡è¯•ä¸€æ¬¡
                response = requests.post(self.api_url, headers=headers, json=data, timeout=60)
                if response.status_code == 200:
                    result = response.json()
                    if isinstance(result, list) and len(result) > 0:
                        return result[0].get('generated_text', '').strip()
                return None
            else:
                logger.error(f"Hugging Face APIé”™è¯¯: {response.status_code} - {response.text}")
                return None

        except Exception as e:
            logger.error(f"Hugging Faceè°ƒç”¨å¤±è´¥: {str(e)}")
            return None

    def generate(self, prompt: str, max_tokens: int = 200) -> Optional[str]:
        """ç”Ÿæˆæ–‡æœ¬"""
        if self.provider in ('openai', 'deepseek', 'kimi'):
            # DeepSeekå’ŒKimiéƒ½ä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼
            return self._call_openai(prompt, max_tokens)
        elif self.provider == 'claude':
            return self._call_claude(prompt, max_tokens)
        elif self.provider == 'huggingface':
            return self._call_huggingface(prompt, max_tokens)

    def summarize_news(self, title: str, content: str, prompt_template: str) -> tuple[Optional[str], Optional[str]]:
        """æ–°é—»æ‘˜è¦ - è¿”å›(ä¸­æ–‡æ ‡é¢˜, è¯¦ç»†æ€»ç»“)"""
        # å¢åŠ å†…å®¹é•¿åº¦åˆ°3000å­—ç¬¦ï¼Œä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯
        content_truncated = content[:3000] if len(content) > 3000 else content
        prompt = prompt_template.format(title=title, content=content_truncated)
        # å¢åŠ è¾“å‡ºé•¿åº¦ä»¥æ”¯æŒè¯¦ç»†æ€»ç»“ï¼ˆæ— å­—æ•°é™åˆ¶ï¼Œè®©AIå……åˆ†è¡¨è¾¾ï¼‰
        result = self.generate(prompt, max_tokens=1500)

        if result:
            # è§£æè¿”å›çš„ä¸­æ–‡æ ‡é¢˜å’Œè¯¦ç»†æ€»ç»“ï¼ˆæŒ‰è¡Œåˆ†å‰²ï¼‰
            lines = result.strip().split('\n')
            lines = [line.strip() for line in lines if line.strip()]

            if len(lines) >= 2:
                chinese_title = lines[0]
                chinese_summary = '\n'.join(lines[1:])
                return chinese_title, chinese_summary
            elif len(lines) == 1:
                # å¦‚æœåªæœ‰ä¸€è¡Œï¼Œä½œä¸ºæ€»ç»“ï¼Œæ ‡é¢˜ä¿æŒåŸæ ·
                return title, lines[0]

        return None, None

    def classify_news(self, title: str, summary: str, prompt_template: str) -> str:
        """æ–°é—»åˆ†ç±»"""
        prompt = prompt_template.format(title=title, summary=summary)
        category = self.generate(prompt, max_tokens=20)

        if category:
            # æ¸…ç†å’ŒéªŒè¯åˆ†ç±»ç»“æœ
            category = category.lower().strip()
            valid_categories = [
                'ai_technology', 'robotics', 'ai_coding_agent', 'semiconductors', 'opcg',
                'automotive', 'consumer_electronics', 'one_piece', 'podcasts',
                'finance_investment', 'business_tech', 'politics_world', 'economy_policy',
                'health_medical', 'energy_environment', 'entertainment_sports',
                'general'
            ]

            for cat in valid_categories:
                if cat in category:
                    return cat

        return 'general'  # é»˜è®¤åˆ†ç±»

    def process_combined(self, title: str, content: str, prompt_template: str) -> tuple[Optional[str], Optional[str], str]:
        """
        åˆå¹¶å¤„ç†ï¼šä¸€æ¬¡è°ƒç”¨å®Œæˆæ‘˜è¦+åˆ†ç±» (Tokenä¼˜åŒ–: èŠ‚çœ50%)
        è¿”å›: (ä¸­æ–‡æ ‡é¢˜, æ‘˜è¦, åˆ†ç±»)
        
        å†…å®¹å¤„ç†ç­–ç•¥:
        - é™åˆ¶è¾“å…¥å†…å®¹é•¿åº¦ï¼Œé¿å…è¶…å‡ºæ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶
        - ä¼˜å…ˆä¿ç•™æ–‡ç« å¼€å¤´éƒ¨åˆ†ï¼ˆé€šå¸¸åŒ…å«å…³é”®ä¿¡æ¯ï¼‰
        """
        # å¢åŠ å†…å®¹æˆªæ–­é•¿åº¦åˆ°3000å­—ç¬¦ï¼Œä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡
        content_truncated = content[:3000] if len(content) > 3000 else content
        prompt = prompt_template.format(title=title, content=content_truncated)
        # å¢åŠ max_tokensä»¥æ”¯æŒæ›´é•¿æ‘˜è¦ï¼ˆæ— å­—æ•°é™åˆ¶ï¼Œè®©AIå……åˆ†è¡¨è¾¾ï¼‰
        result = self.generate(prompt, max_tokens=1500)

        if result:
            try:
                # å°è¯•è§£æJSON
                import json
                # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
                cleaned = result.strip()
                if cleaned.startswith('```'):
                    # ç§»é™¤å¼€å¤´çš„```jsonæˆ–```
                    cleaned = '\n'.join(cleaned.split('\n')[1:])
                if cleaned.endswith('```'):
                    # ç§»é™¤ç»“å°¾çš„```
                    cleaned = '\n'.join(cleaned.split('\n')[:-1])

                data = json.loads(cleaned.strip())
                chinese_title = data.get('title', title)
                chinese_summary = data.get('summary', '')
                category = data.get('category', 'general')

                # éªŒè¯åˆ†ç±»
                valid_categories = [
                    'ai_technology', 'robotics', 'ai_coding_agent', 'semiconductors', 'opcg',
                    'automotive', 'consumer_electronics', 'one_piece', 'anime_otaku', 'podcasts',
                    'finance_investment', 'business_tech', 'politics_world', 'economy_policy',
                    'health_medical', 'energy_environment', 'entertainment_sports',
                    'general'
                ]

                if category not in valid_categories:
                    # å°è¯•ä»åˆ†ç±»å­—ç¬¦ä¸²ä¸­æå–
                    for cat in valid_categories:
                        if cat in category.lower():
                            category = cat
                            break
                    else:
                        category = 'general'

                logger.debug(f"âœ… æˆåŠŸè§£æAIå“åº”: æ ‡é¢˜={chinese_title[:30]}..., åˆ†ç±»={category}")
                return chinese_title, chinese_summary, category

            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                logger.debug(f"   AIè¿”å›å†…å®¹: {result[:200]}...")
                # Fallback: å°è¯•åˆ†è¡Œè§£æ
                lines = result.strip().split('\n')
                lines = [line.strip() for line in lines if line.strip()]
                if len(lines) >= 2:
                    logger.debug(f"   ä½¿ç”¨fallbackè§£æ: {len(lines)} è¡Œ")
                    return lines[0], '\n'.join(lines[1:-1]), lines[-1] if len(lines) > 2 else 'general'
            except Exception as e:
                logger.error(f"âŒ å¤„ç†AIå“åº”æ—¶å‡ºé”™: {str(e)}")

        logger.warning(f"âš ï¸ AIå¤„ç†è¿”å›ç©ºç»“æœï¼Œå°†ä½¿ç”¨fallback")
        return None, None, 'general'


class NewsProcessor:
    """æ–°é—»å¤„ç†å™¨ï¼ˆäº‘ç«¯ç‰ˆæœ¬ï¼‰"""

    def __init__(self, ai_provider: str = 'openai'):
        """
        åˆå§‹åŒ–å¤„ç†å™¨

        Args:
            ai_provider: 'openai' æˆ– 'claude'
        """
        try:
            self.ai = CloudAIProcessor(ai_provider)
            logger.info(f"ä½¿ç”¨äº‘ç«¯AI: {ai_provider}")
        except ValueError as e:
            logger.error(f"AIåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    def process_news(self, news_item: Dict, summarize_prompt: str, classify_prompt: str) -> Dict:
        """å¤„ç†å•æ¡æ–°é—»"""
        try:
            # 1. ç”Ÿæˆä¸­æ–‡æ ‡é¢˜å’Œæ‘˜è¦
            chinese_title, chinese_summary = self.ai.summarize_news(
                news_item['title'],
                news_item['content'],
                summarize_prompt
            )

            if not chinese_title or not chinese_summary:
                logger.warning(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨fallback: {news_item['title']}")
                chinese_title = news_item['title'][:100]  # é™åˆ¶é•¿åº¦
                # fallbackæ—¶ä¿ç•™æ›´å¤šå†…å®¹ï¼ˆ500å­—ç¬¦ï¼‰
                content = news_item['content']
                chinese_summary = content[:500] + '...' if len(content) > 500 else content
                if not chinese_summary:
                    chinese_summary = 'æš‚æ— æ‘˜è¦'

            # 2. åˆ†ç±»
            category = self.ai.classify_news(
                chinese_title,
                chinese_summary,
                classify_prompt
            )

            # 3. æ„å»ºå¤„ç†åçš„æ–°é—»
            processed_news = {
                'title': chinese_title,  # ä½¿ç”¨ä¸­æ–‡æ ‡é¢˜
                'summary': chinese_summary,  # ä½¿ç”¨ä¸­æ–‡ç®€æŠ¥
                'category': category,
                'source': news_item['source'],
                'source_url': news_item['source_url'],
                'link': news_item['link'],
                'image': news_item.get('image'),
                'video': news_item.get('video'),  # æ·»åŠ videoå­—æ®µ
                'published': news_item['published'],
                'created_at': news_item.get('created_at'),
                'source_type': news_item.get('source_type', 'rss')  # ä¿ç•™æ¥æºç±»å‹
            }
            
            # è§†é¢‘ç‰¹æœ‰å­—æ®µ
            if news_item.get('source_type') == 'youtube':
                if 'video_duration' in news_item:
                    processed_news['video_duration'] = news_item['video_duration']
                if 'video_author' in news_item:
                    processed_news['video_author'] = news_item['video_author']
                if 'video_views' in news_item:
                    processed_news['video_views'] = news_item['video_views']

            logger.info(f"å¤„ç†å®Œæˆ: [{category}] {chinese_title[:30]}...")
            return processed_news

        except Exception as e:
            logger.error(f"æ–°é—»å¤„ç†å¤±è´¥: {str(e)}")
            return None

    def process_news_combined(self, news_item: Dict, combined_prompt: str) -> Dict:
        """
        ä½¿ç”¨åˆå¹¶æç¤ºè¯å¤„ç†å•æ¡æ–°é—» (Tokenä¼˜åŒ–: ä¸€æ¬¡è°ƒç”¨å®Œæˆæ‘˜è¦+åˆ†ç±»)
        """
        try:
            original_title = news_item.get('title', '')
            content = news_item.get('content', '')
            
            logger.debug(f"ğŸ“ å¤„ç†æ–°é—»: {original_title[:50]}...")
            
            # ä½¿ç”¨åˆå¹¶æç¤ºè¯ä¸€æ¬¡æ€§å®Œæˆæ‘˜è¦å’Œåˆ†ç±»
            chinese_title, chinese_summary, category = self.ai.process_combined(
                original_title,
                content,
                combined_prompt
            )

            if not chinese_title or not chinese_summary:
                logger.debug(f"   AIè¿”å›ç©ºç»“æœï¼Œä½¿ç”¨fallbackå¤„ç†")
                chinese_title = original_title[:100]
                # fallbackæ—¶ä¿ç•™æ›´å¤šå†…å®¹ï¼ˆ500å­—ç¬¦ï¼‰
                chinese_summary = content[:500] + '...' if len(content) > 500 else content
                if not chinese_summary:
                    chinese_summary = 'æš‚æ— æ‘˜è¦'
                category = 'general'
                logger.debug(f"   Fallbackåˆ†ç±»: {category}")
            else:
                logger.debug(f"   AIå¤„ç†æˆåŠŸ: åˆ†ç±»={category}")

            # æ„å»ºå¤„ç†åçš„æ–°é—»
            processed_news = {
                'title': chinese_title,
                'summary': chinese_summary,
                'category': category,
                'source': news_item['source'],
                'source_url': news_item['source_url'],
                'link': news_item['link'],
                'image': news_item.get('image'),
                'video': news_item.get('video'),
                'published': news_item['published'],
                'created_at': news_item.get('created_at'),
                'source_type': news_item.get('source_type', 'rss')  # ä¿ç•™æ¥æºç±»å‹
            }
            
            # è§†é¢‘ç‰¹æœ‰å­—æ®µ
            if news_item.get('source_type') == 'youtube':
                if 'video_duration' in news_item:
                    processed_news['video_duration'] = news_item['video_duration']
                if 'video_author' in news_item:
                    processed_news['video_author'] = news_item['video_author']
                if 'video_views' in news_item:
                    processed_news['video_views'] = news_item['video_views']

            return processed_news

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–°é—»å¤±è´¥: {str(e)[:100]}")
            logger.debug(f"   æ ‡é¢˜: {news_item.get('title', 'N/A')[:50]}...")
            return None

    def batch_process(self, news_list: list, summarize_prompt: str, classify_prompt: str) -> list:
        """æ‰¹é‡å¤„ç†æ–°é—»ï¼ˆä½¿ç”¨å¹¶å‘åŠ é€Ÿï¼‰"""
        start_time = datetime.now()

        # è·å–å¹¶å‘çº¿ç¨‹æ•°ï¼ˆä»ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨é»˜è®¤å€¼5ï¼‰
        max_workers = int(os.getenv('AI_CONCURRENT_WORKERS', 5))

        logger.info(f"å¼€å§‹å¹¶å‘å¤„ç† {len(news_list)} æ¡æ–°é—»ï¼ˆ{max_workers}ä¸ªçº¿ç¨‹ï¼‰...")

        processed = []
        failed = []

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_news = {
                executor.submit(self.process_news, news, summarize_prompt, classify_prompt): news
                for news in news_list
            }

            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            completed_count = 0
            for future in as_completed(future_to_news):
                news = future_to_news[future]
                completed_count += 1

                try:
                    result = future.result(timeout=120)  # å¢åŠ è¶…æ—¶åˆ°120ç§’ï¼Œé¿å…é•¿å†…å®¹å¤„ç†å¤±è´¥  # å•æ¡æ–°é—»æœ€å¤š60ç§’
                    if result:
                        processed.append(result)
                        # æ¯10æ¡æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
                        if completed_count % 10 == 0:
                            logger.info(f"è¿›åº¦: {completed_count}/{len(news_list)} æ¡å·²å¤„ç†")
                    else:
                        failed.append(news['title'][:50])
                        logger.warning(f"å¤„ç†å¤±è´¥: {news['title'][:50]}")
                except Exception as e:
                    failed.append(news['title'][:50])
                    logger.error(f"å¤„ç†å¼‚å¸¸: {news['title'][:50]} - {str(e)}")

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        elapsed = (datetime.now() - start_time).total_seconds()
        success_rate = len(processed) / len(news_list) * 100 if news_list else 0
        avg_time_per_news = elapsed / len(news_list) if news_list else 0

        logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: {len(processed)}/{len(news_list)} ({success_rate:.1f}%)")
        logger.info(f"æ€»è€—æ—¶: {elapsed:.1f}ç§’, å¹³å‡: {avg_time_per_news:.2f}ç§’/æ¡")

        # å¦‚æœå¤±è´¥ç‡è¶…è¿‡10%ï¼Œè®°å½•è­¦å‘Š
        if success_rate < 90 and len(news_list) > 0:
            logger.warning(f"âš ï¸  é«˜å¤±è´¥ç‡æ£€æµ‹: {100-success_rate:.1f}% çš„æ–°é—»å¤„ç†å¤±è´¥")
            logger.warning(f"å¤±è´¥çš„æ–°é—»ç¤ºä¾‹: {failed[:3]}")

        return processed

    def batch_process_combined(self, news_list: list, combined_prompt: str) -> list:
        """
        æ‰¹é‡å¤„ç†æ–°é—»ï¼ˆä½¿ç”¨åˆå¹¶æç¤ºè¯ï¼ŒTokenä¼˜åŒ–: ä¸€æ¬¡è°ƒç”¨å®Œæˆæ‘˜è¦+åˆ†ç±»ï¼‰
        """
        start_time = datetime.now()

        # è·å–å¹¶å‘çº¿ç¨‹æ•°
        max_workers = int(os.getenv('AI_CONCURRENT_WORKERS', 5))

        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡AIå¤„ç†: {len(news_list)} æ¡æ–°é—»")
        logger.info(f"   å¹¶å‘çº¿ç¨‹: {max_workers}ä¸ª")
        logger.info(f"   AI Provider: {self.ai.provider}")
        logger.info(f"   æ¨¡å‹: {self.ai.model}")

        processed = []
        failed = []
        api_errors = 0

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_news = {
                executor.submit(self.process_news_combined, news, combined_prompt): news
                for news in news_list
            }

            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            completed_count = 0
            for future in as_completed(future_to_news):
                news = future_to_news[future]
                completed_count += 1

                try:
                    result = future.result(timeout=60)
                    if result:
                        processed.append(result)
                        if completed_count % 5 == 0 or completed_count == len(news_list):
                            logger.info(f"   è¿›åº¦: {completed_count}/{len(news_list)} æ¡å·²å¤„ç† ({completed_count/len(news_list)*100:.0f}%)")
                    else:
                        failed.append(news['title'][:50])
                        api_errors += 1
                        if api_errors <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªå¤±è´¥
                            logger.warning(f"   âš ï¸ å¤„ç†å¤±è´¥ ({api_errors}): {news['title'][:50]}...")
                except Exception as e:
                    failed.append(news['title'][:50])
                    api_errors += 1
                    if api_errors <= 3:
                        logger.error(f"   âŒ å¤„ç†å¼‚å¸¸ ({api_errors}): {news['title'][:50]}... - {str(e)[:50]}")
                        
        # å¦‚æœæœ‰å¤±è´¥çš„æ–°é—»ï¼Œå°è¯•ç®€åŒ–é‡è¯•
        if failed and len(failed) > 0:
            logger.info(f"   å°è¯•ç®€åŒ–å¤„ç† {len(failed)} æ¡å¤±è´¥æ–°é—»...")
            for news_title in failed[:3]:  # æœ€å¤šé‡è¯•3æ¡
                # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€åŒ–é‡è¯•é€»è¾‘
                pass

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        elapsed = (datetime.now() - start_time).total_seconds()
        success_rate = len(processed) / len(news_list) * 100 if news_list else 0
        avg_time_per_news = elapsed / len(news_list) if news_list else 0

        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ:")
        logger.info(f"   æˆåŠŸ: {len(processed)}/{len(news_list)} ({success_rate:.1f}%)")
        logger.info(f"   å¤±è´¥: {len(failed)}")
        logger.info(f"   æ€»è€—æ—¶: {elapsed:.1f}ç§’")
        logger.info(f"   å¹³å‡: {avg_time_per_news:.2f}ç§’/æ¡")

        if success_rate < 90 and len(news_list) > 0:
            logger.warning(f"âš ï¸  é«˜å¤±è´¥ç‡è­¦å‘Š: {100-success_rate:.1f}% çš„æ–°é—»å¤„ç†å¤±è´¥")
            if failed:
                logger.warning(f"   å¤±è´¥ç¤ºä¾‹: {failed[:3]}")

        return processed
